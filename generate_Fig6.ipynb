{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afbf13c-c8ef-406a-9ae7-275164d1707c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from matplotlib import cm\n",
    "\n",
    "from tiatoolbox.wsicore.wsireader import WSIReader\n",
    "from tiatoolbox.models.engine.patch_predictor import PatchPredictor\n",
    "from tiatoolbox.utils.visualization import overlay_prediction_mask\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import re\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220fcc3b-a084-4f02-8d8c-9b60d17ac9da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_he_path    = Path('CRC2/data_CRC37_19510_C37_US_SCAN_OR_001__161733-registered.ome.tif')\n",
    "virtual_he_path = Path('CRC2/H&E/data_CRC37_P37_S80_Full_A24_C59qX_E15_20220307_235159_333000-zlib.ome.tiff')\n",
    "\n",
    "# Model-native tile size/stride in OUTPUT pixels\n",
    "PATCH_SIZE = (224, 224)  # (H, W)\n",
    "STRIDE     = (224, 224)  # (H, W)\n",
    "\n",
    "# Read patches ~0.5 mpp; merge/overlay ~4.0 mpp (tuples for anisotropy safety)\n",
    "INPUT_RES_MPP  = (0.5, 0.5)\n",
    "MERGE_RES_MPP  = (4.0, 4.0)\n",
    "\n",
    "# Inference micro-batch size\n",
    "BATCH_INFER = 256\n",
    "\n",
    "# Label mapping for Kather100K 9-class CRC model\n",
    "label_dict = {\n",
    "    \"BACK\": 0, \"NORM\": 1, \"DEB\":  2, \"TUM\":  3, \"ADI\":  4,\n",
    "    \"MUC\":  5, \"MUS\":  6, \"STR\":  7, \"LYM\":  8,\n",
    "}\n",
    "id_to_name = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "# Colors for overlay (RGB)\n",
    "label_info = {\n",
    "    0: (\"Background\", (153, 153, 153)),  # Set1 gray   #999999\n",
    "    1: (\"Normal mucosa\", (255, 127,   0)),  # Set1 orange #ff7f00  \n",
    "    2: (\"Debris\",  (166,  86,  40)),  # Set1 brown  #a65628\n",
    "    3: (\"Tumor epithelium\",  (228,  26,  28)),  # Set1 red    #e41a1c\n",
    "    4: (\"Adipose tissue\",  (255, 255,  51)),  # Set1 yellow #ffff33\n",
    "    5: (\"Mucus\",  ( 77, 175,  74)),  # Set1 green  #4daf4a\n",
    "    6: (\"Smooth muscle\",  (247, 129, 191)),  # Set1 pink   #f781bf\n",
    "    7: (\"Stroma\",  ( 55, 126, 184)),  # Set1 blue   #377eb8\n",
    "    8: (\"Lymphocytes\",  (152,  78, 163)),  # Set1 purple #984ea3\n",
    "}\n",
    "\n",
    "# -------------------- MODEL --------------------\n",
    "predictor = PatchPredictor(\n",
    "    pretrained_model=\"resnet34-kather100k\",\n",
    "    # pretrained_weights=weights_path,\n",
    "    batch_size=64,\n",
    "    num_loader_workers=4,\n",
    "    # device=\"cuda\",\n",
    ")\n",
    "\n",
    "# -------------------- HELPERS --------------------\n",
    "def _res_tuple(res):\n",
    "    if isinstance(res, (int, float)):\n",
    "        return (float(res), float(res))\n",
    "    return (float(res[0]), float(res[1]))\n",
    "\n",
    "def _slide_dims_at_res(wsi_reader, res_mpp_xy):\n",
    "    \"\"\"Return (W,H) slide dimensions in pixels at the requested mpp (resolution space).\"\"\"\n",
    "    res_mpp_xy = _res_tuple(res_mpp_xy)\n",
    "    try:\n",
    "        return wsi_reader.slide_dimensions(resolution=res_mpp_xy, units=\"mpp\")\n",
    "    except TypeError:\n",
    "        # Older builds accept scalar; use x-axis\n",
    "        return wsi_reader.slide_dimensions(resolution=float(res_mpp_xy[0]), units=\"mpp\")\n",
    "\n",
    "def generate_coords_resolution_space(img_size_wh_res, patch_hw, stride_hw):\n",
    "    \"\"\"Grid of top-left (x,y) in RESOLUTION space (same pixels as PATCH_SIZE/STRIDE).\"\"\"\n",
    "    W_res, H_res = map(int, img_size_wh_res)\n",
    "    ph, pw = map(int, patch_hw)    # (H,W)\n",
    "    sh, sw = map(int, stride_hw)   # (H,W)\n",
    "\n",
    "    if ph <= 0 or pw <= 0:\n",
    "        return np.zeros((0, 2), dtype=np.int32)\n",
    "\n",
    "    max_x_start = max(W_res - pw, 0)\n",
    "    max_y_start = max(H_res - ph, 0)\n",
    "\n",
    "    xs = np.arange(0, max_x_start + 1, max(1, sw), dtype=np.int32)\n",
    "    ys = np.arange(0, max_y_start + 1, max(1, sh), dtype=np.int32)\n",
    "    if xs.size == 0 or ys.size == 0:\n",
    "        return np.zeros((0, 2), dtype=np.int32)\n",
    "\n",
    "    gx, gy = np.meshgrid(xs, ys)\n",
    "    return np.stack([gx.ravel(), gy.ravel()], axis=1).astype(np.int32)\n",
    "\n",
    "class OnTheFlyWSIPatchDataset:\n",
    "    \"\"\"Read patches at a physical resolution using RESOLUTION-SPACE coords.\"\"\"\n",
    "    def __init__(self, wsi_reader, coords_res_xy, patch_size_hw, resolution_mpp_xy):\n",
    "        self.wsi = wsi_reader\n",
    "        self.coords = np.asarray(coords_res_xy, dtype=np.int32)  # (x,y) in resolution-space\n",
    "        self.size_wh = (int(patch_size_hw[1]), int(patch_size_hw[0]))  # (W,H)\n",
    "        self.res_mpp_xy = _res_tuple(resolution_mpp_xy)\n",
    "\n",
    "    def __len__(self): return int(self.coords.shape[0])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x, y = map(int, self.coords[i])\n",
    "        img = self.wsi.read_rect(\n",
    "            location=(x, y),\n",
    "            size=self.size_wh,\n",
    "            resolution=self.res_mpp_xy,\n",
    "            units=\"mpp\",\n",
    "            coord_space=\"resolution\",     # << CRUCIAL\n",
    "        )\n",
    "        return {\"image\": img}\n",
    "\n",
    "def infer_patches_in_batches(predictor, dataset, batch_size=BATCH_INFER):\n",
    "    preds_all, batch_imgs = [], []\n",
    "    N = len(dataset)\n",
    "    for i in range(N):\n",
    "        batch_imgs.append(dataset[i][\"image\"])\n",
    "        if len(batch_imgs) == batch_size or (i + 1) == N:\n",
    "            out = predictor.predict(imgs=batch_imgs, mode=\"patch\", return_probabilities=False)\n",
    "            preds_all.extend(list(out[\"predictions\"]))\n",
    "            batch_imgs = []\n",
    "    return np.asarray(preds_all, dtype=np.int16)\n",
    "\n",
    "# -------------------- CORE PIPELINE --------------------\n",
    "def run_wsi(img_path: Path, tag: str):\n",
    "    if not img_path.exists():\n",
    "        raise FileNotFoundError(f\"WSI not found: {img_path.resolve()}\")\n",
    "\n",
    "    # 1) Open reader & get slide size in RESOLUTION space at INPUT_RES_MPP\n",
    "    wsi_reader = WSIReader.open(img_path)\n",
    "    slide_wh_res = _slide_dims_at_res(wsi_reader, INPUT_RES_MPP)   # (W_res, H_res)\n",
    "    W_res, H_res = map(int, slide_wh_res)\n",
    "\n",
    "    # 2) Compute grid shape in RESOLUTION space\n",
    "    ph, pw = map(int, PATCH_SIZE)           # (H,W) in output pixels\n",
    "    sh, sw = map(int, STRIDE)               # (H,W) in output pixels\n",
    "    Nx = 0 if W_res < pw else ((W_res - pw) // sw + 1)\n",
    "    Ny = 0 if H_res < ph else ((H_res - ph) // sh + 1)\n",
    "\n",
    "    # 3) Build grid coordinates (same order as earlier code)\n",
    "    coords_res = generate_coords_resolution_space(\n",
    "        img_size_wh_res=slide_wh_res,\n",
    "        patch_hw=PATCH_SIZE,\n",
    "        stride_hw=STRIDE,\n",
    "    )\n",
    "    assert coords_res.shape[0] == Ny * Nx, (\n",
    "        f\"Grid size mismatch: coords={coords_res.shape[0]} vs Ny*Nx={Ny*Nx}\"\n",
    "    )\n",
    "\n",
    "    # 4) Dataset & inference\n",
    "    dataset = OnTheFlyWSIPatchDataset(\n",
    "        wsi_reader=wsi_reader,\n",
    "        coords_res_xy=coords_res,\n",
    "        patch_size_hw=PATCH_SIZE,\n",
    "        resolution_mpp_xy=INPUT_RES_MPP,\n",
    "    )\n",
    "    pred_ids = infer_patches_in_batches(predictor, dataset, batch_size=BATCH_INFER)\n",
    "\n",
    "    # 5) Boxes for merge in RESOLUTION space (x0,y0,x1,y1)\n",
    "    x0y0 = coords_res.astype(np.int32)\n",
    "    x1y1 = x0y0 + np.asarray([pw, ph], dtype=np.int32)  # add (W,H)\n",
    "    coords_boxes = np.hstack([x0y0, x1y1]).astype(np.int32)\n",
    "\n",
    "    # 6) Merge to dense map\n",
    "    out_for_merge = {\n",
    "        \"coordinates\": coords_boxes,\n",
    "        \"predictions\": pred_ids,\n",
    "        \"resolution\": _res_tuple(INPUT_RES_MPP),\n",
    "        \"units\": \"mpp\",\n",
    "    }\n",
    "    pred_map = predictor.merge_predictions(\n",
    "        wsi_reader,\n",
    "        out_for_merge,\n",
    "        resolution=_res_tuple(MERGE_RES_MPP),\n",
    "        units=\"mpp\",\n",
    "    )\n",
    "\n",
    "    # 7) Overlay background aligned to pred_map\n",
    "    h, w = pred_map.shape[:2]\n",
    "    rgb_for_overlay = wsi_reader.read_rect(\n",
    "        location=(0, 0),\n",
    "        size=(int(w), int(h)),\n",
    "        resolution=_res_tuple(MERGE_RES_MPP),\n",
    "        units=\"mpp\",\n",
    "        coord_space=\"resolution\",\n",
    "    )\n",
    "\n",
    "    # 8) Quicklooks\n",
    "    max_side = 1024\n",
    "    Hs, Ws = rgb_for_overlay.shape[:2]\n",
    "    scale = max(Hs, Ws) / float(max_side)\n",
    "    new_w, new_h = (int(round(Ws / scale)), int(round(Hs / scale))) if scale > 1.0 else (Ws, Hs)\n",
    "    thumb_rgb = cv2.resize(rgb_for_overlay, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    pm_small  = cv2.resize(pred_map.astype(np.int16), (new_w, new_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    ax1 = overlay_prediction_mask(\n",
    "        img=thumb_rgb, prediction=pm_small, alpha=0.45, label_info=label_info, return_ax=True\n",
    "    )\n",
    "    fig1 = ax1.get_figure()\n",
    "    fig1.suptitle(f\"{tag} — Thumbnail overlay\", y=1.02)\n",
    "    plt.show()\n",
    "    plt.close(fig1)\n",
    "\n",
    "    print(f\"[{tag}] tiles: Ny={Ny}, Nx={Nx}\")\n",
    "\n",
    "    # Reshape predictions into a (Ny, Nx) grid using the same row-major order\n",
    "    pred_grid = pred_ids.reshape(Ny, Nx)\n",
    "\n",
    "    return {\n",
    "        \"pred_map\": pred_map,\n",
    "        \"grid_shape\": (Ny, Nx),\n",
    "        \"pred_grid\": pred_grid,\n",
    "    }\n",
    "\n",
    "# -------------------- RUN ON BOTH WSIs --------------------\n",
    "virt_res = run_wsi(virtual_he_path, tag=\"virtual_HE\")\n",
    "real_res = run_wsi(real_he_path,    tag=\"real_HE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9f6d0d-6f30-4f48-bad2-e66153c93359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TITLE_FSIZE  = 16   # titles above each panel\n",
    "LEGEND_FSIZE = 14   # legend text\n",
    "SQUARE_SIZE  = 14   # legend square size\n",
    "\n",
    "# Legend handles with FULL names, drawn as true squares\n",
    "legend_handles = []\n",
    "for cid, (name, rgb) in sorted(label_info.items()):\n",
    "    legend_handles.append(\n",
    "        Line2D(\n",
    "            [0], [0],\n",
    "            marker='s', linestyle='None',\n",
    "            markersize=SQUARE_SIZE,\n",
    "            markerfacecolor=np.array(rgb)/255.0,\n",
    "            markeredgecolor='black',\n",
    "            markeredgewidth=0.8,\n",
    "            label=name\n",
    "        )\n",
    "    )\n",
    "\n",
    "def _color_lut_from_label_info(label_info):\n",
    "    max_id = max(label_info.keys())\n",
    "    lut = np.zeros((max_id + 1, 3), dtype=np.uint8)\n",
    "    for cid, (_, rgb) in label_info.items():\n",
    "        lut[int(cid)] = np.array(rgb, dtype=np.uint8)\n",
    "    return lut\n",
    "\n",
    "def _labels_rgb_from_pred(pred_map, label_info):\n",
    "    \"\"\"Return a colorized label image (no H&E) from an integer pred_map.\"\"\"\n",
    "    lut = _color_lut_from_label_info(label_info)\n",
    "    pred_clipped = np.clip(pred_map.astype(np.int32), 0, lut.shape[0]-1)\n",
    "    return lut[pred_clipped]  # [H,W,3] uint8\n",
    "\n",
    "def _read_rgb_at_merge(wsi_path, target_wh, res_mpp=(4.0, 4.0)):\n",
    "    from tiatoolbox.wsicore.wsireader import WSIReader\n",
    "    wsi = WSIReader.open(wsi_path)\n",
    "    w, h = int(target_wh[0]), int(target_wh[1])\n",
    "    return wsi.read_rect(location=(0, 0), size=(w, h),\n",
    "                         resolution=res_mpp, units=\"mpp\", coord_space=\"resolution\")\n",
    "\n",
    "def _resize_pair(rgb, pred_map, target_wh):\n",
    "    Wt, Ht = int(target_wh[0]), int(target_wh[1])\n",
    "    rgb_r  = cv2.resize(rgb, (Wt, Ht), interpolation=cv2.INTER_AREA)\n",
    "    pm_r   = cv2.resize(pred_map.astype(np.int16), (Wt, Ht), interpolation=cv2.INTER_NEAREST)\n",
    "    return rgb_r, pm_r\n",
    "\n",
    "def show_wsi_comparison_clean(\n",
    "    real_res, virt_res, real_path, virt_path, label_info, merge_res_mpp=(4.0, 4.0), target=\"min\"\n",
    "):\n",
    "    # Choose a common canvas size at MERGE resolution\n",
    "    Hr, Wr = real_res[\"pred_map\"].shape[:2]\n",
    "    Hv, Wv = virt_res[\"pred_map\"].shape[:2]\n",
    "    if target == \"max\":\n",
    "        Wt, Ht = max(Wr, Wv), max(Hr, Hv)\n",
    "    else:\n",
    "        Wt, Ht = min(Wr, Wv), min(Hr, Hv)\n",
    "\n",
    "    # Read H&E images at the common size\n",
    "    rgb_real = _read_rgb_at_merge(real_path, (Wt, Ht), res_mpp=merge_res_mpp)\n",
    "    rgb_virt = _read_rgb_at_merge(virt_path, (Wt, Ht), res_mpp=merge_res_mpp)\n",
    "\n",
    "    # Resize prediction maps to the same size\n",
    "    _, real_pm = _resize_pair(rgb_real, real_res[\"pred_map\"], (Wt, Ht))\n",
    "    _, virt_pm = _resize_pair(rgb_virt, virt_res[\"pred_map\"], (Wt, Ht))\n",
    "\n",
    "    # Labels-only (colorized) images\n",
    "    labels_real_rgb = _labels_rgb_from_pred(real_pm, label_info)\n",
    "    labels_virt_rgb = _labels_rgb_from_pred(virt_pm, label_info)\n",
    "\n",
    "    # Plot (same compact spacing you liked)\n",
    "    fig, axes = plt.subplots(\n",
    "        2, 2, figsize=(10, 8),\n",
    "        gridspec_kw={'hspace': 0.05, 'wspace': 0.05}\n",
    "    )\n",
    "\n",
    "    axes[0,0].imshow(rgb_real);\n",
    "    axes[0,0].set_title(\"Real H&E\", fontsize=TITLE_FSIZE, pad=4);\n",
    "    axes[0,0].axis(\"off\")\n",
    "    axes[0,1].imshow(labels_real_rgb, interpolation=\"nearest\");\n",
    "    axes[0,1].set_title(\"Predictions on real H&E\",    fontsize=TITLE_FSIZE, pad=4);\n",
    "    axes[0,1].axis(\"off\")\n",
    "    \n",
    "    axes[1,0].imshow(rgb_virt);\n",
    "    axes[1,0].set_title(\"Virtual H&E\", fontsize=TITLE_FSIZE, pad=4);\n",
    "    axes[1,0].axis(\"off\")\n",
    "    axes[1,1].imshow(labels_virt_rgb, interpolation=\"nearest\");\n",
    "    axes[1,1].set_title(\"Predictions on virtual H&E\", fontsize=TITLE_FSIZE, pad=4);\n",
    "    axes[1,1].axis(\"off\")\n",
    "\n",
    "\n",
    "    # After plotting each image:\n",
    "    for ax in axes.flat:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # add a rectangle the size of the axes\n",
    "        ax.add_patch(Rectangle(\n",
    "            (0, 0), 1, 1, transform=ax.transAxes,\n",
    "            fill=False, color=\"black\", linewidth=1.5\n",
    "        ))\n",
    "        \n",
    "    # Move legend a bit right and enlarge font\n",
    "    fig.legend(\n",
    "        handles=legend_handles,\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(0.91, 0.88),\n",
    "        fontsize=LEGEND_FSIZE,\n",
    "        frameon=False,\n",
    "        ncol=3,\n",
    "        handlelength=0.0,\n",
    "        labelspacing=0.6,\n",
    "        borderpad=0.2\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "show_wsi_comparison_clean(\n",
    "    real_res=real_res,\n",
    "    virt_res=virt_res,\n",
    "    real_path=real_he_path,\n",
    "    virt_path=virtual_he_path,\n",
    "    label_info=label_info,\n",
    "    merge_res_mpp=(4.0, 4.0),\n",
    "    target=\"min\",  # or \"max\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c1813-9535-4957-817f-65d5753f749e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------- Ensure run_wsi (from your inference block) is available --------\n",
    "try:\n",
    "    run_wsi  # noqa: F401\n",
    "except NameError as _:\n",
    "    raise RuntimeError(\"run_wsi(...) not found. Run your TIAToolbox inference block first.\")\n",
    "\n",
    "# -------- Save directory for per-pair outputs --------\n",
    "SAVE_DIR = Path(\"evaluation_data\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------- Label mapping (Kather100K, 9 classes) --------\n",
    "label_dict = {\n",
    "    \"BACK\": 0, \"NORM\": 1, \"DEB\":  2, \"TUM\":  3, \"ADI\":  4,\n",
    "    \"MUC\":  5, \"MUS\":  6, \"STR\":  7, \"LYM\":  8,\n",
    "}\n",
    "num_classes = max(label_dict.values()) + 1\n",
    "BACK_ID = label_dict[\"BACK\"]\n",
    "\n",
    "# Pretty (full) tissue names (maps id -> full string)\n",
    "full_label_names = {\n",
    "    \"BACK\": \"Background\",\n",
    "    \"NORM\": \"Normal mucosa\",\n",
    "    \"DEB\":  \"Debris\",\n",
    "    \"TUM\":  \"Tumor epithelium\",\n",
    "    \"ADI\":  \"Adipose tissue\",\n",
    "    \"MUC\":  \"Mucus\",\n",
    "    \"MUS\":  \"Smooth muscle\",\n",
    "    \"STR\":  \"Stroma\",\n",
    "    \"LYM\":  \"Lymphocytes\",\n",
    "}\n",
    "id_to_full = {label_dict[k]: v for k, v in full_label_names.items()}\n",
    "\n",
    "# -------- Define the list of image pairs (virtual, real) --------\n",
    "image_pairs = [\n",
    "    ('CRC2/H&E/data_CRC01_P37_S29_A24_C59kX_E15_20220106_014304_946511-zlib.ome.tiff', 'CRC2/data_CRC01_18459_LSP10353_US_SCAN_OR_001__093059-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC02_P37_S30_A24_C59kX_E15_20220106_014319_409148-zlib.ome.tiff', 'CRC2/data_CRC02_18459_LSP10364_US_SCAN_OR_001__092347-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC03_P37_S31_A24_C59kX_E15_20220106_014409_014236-zlib.ome.tiff', 'CRC2/data_CRC03_18459_LSP10375_US_SCAN_OR_001__092147-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC04_P37_S32_A24_C59kX_E15_20220106_014630_553652-zlib.ome.tiff', 'CRC2/data_CRC04_18459_LSP10388_US_SCAN_OR_001__091155-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC05_P37_S33_A24_C59kX_E15_20220107_180446_881530-zlib.ome.tiff', 'CRC2/data_CRC05_18459_LSP10397_US_SCAN_OR_001__091631-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC06_P37_S34_A24_C59kX_E15_20220107_202112_212579-zlib.ome.tiff', 'CRC2/data_CRC06_18459_LSP10408_US_SCAN_OR_001__092559-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC07_P37_S35_A24_C59kX_E15_20220108_012037_490594-zlib.ome.tiff', 'CRC2/data_CRC07_18459_LSP10419_US_SCAN_OR_001__090907-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC08_P37_S57_Full_A24_C59nX_E15_20220224_011032_774034-zlib.ome.tiff', 'CRC2/data_CRC08_19510_C8_US_SCAN_OR_001__150825-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC09_P37_S37_A24_C59kX_E15_20220108_012113_953544-zlib.ome.tiff', 'CRC2/data_CRC09_18459_LSP10441_US_SCAN_OR_001__091844-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC10_P37_S38_A24_C59kX_E15_20220108_012130_664519-zlib.ome.tiff', 'CRC2/data_CRC10_18459_LSP10452_US_SCAN_OR_001__091355-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC11_P37_S43_Full_A24_C59mX_E15_20220128_171510_544056-zlib.ome.tiff', 'CRC2/data_CRC11_19510_C11_US_SCAN_OR_001__151039-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC12_P37_S44_Full_A24_C59mX_E15_20220128_171448_903938-zlib.ome.tiff', 'CRC2/data_CRC12_19510_C12_US_SCAN_OR_001__151249-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC13_P37_S45_Full_A24_C59mX_E15_20220128_171409_633341-zlib.ome.tiff', 'CRC2/data_CRC13_19510_C13_US_SCAN_OR_001__151503-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC14_P37_S46_Full_A24_C59mX_E15_20220128_013821_398547-zlib.ome.tiff', 'CRC2/data_CRC14_19510_C14_US_SCAN_OR_001__151737-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC15_P37_S47_Full_A24_C59mX_E15_20220128_020654_901143-zlib.ome.tiff', 'CRC2/data_CRC15_19510_C15_US_SCAN_OR_001__152234-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC16_P37_S48_Full_A24_C59mX_E15_20220129_015105_865195-zlib.ome.tiff', 'CRC2/data_CRC16_19510_C16_US_SCAN_OR_001__152020-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC17_P37_S49_Full_A24_C59mX_E15_20220129_015121_911264-zlib.ome.tiff', 'CRC2/data_CRC17_19510_C17_US_SCAN_OR_001__152525-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC18_P37_S50_Full_A24_C59mX_E15_20220129_015242_755602-zlib.ome.tiff', 'CRC2/data_CRC18_19510_C18_US_SCAN_OR_001__152757-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC19_P37_S51_Full_A24_C59mX_E15_20220129_015300_669681-zlib.ome.tiff', 'CRC2/data_CRC19_19510_C19_US_SCAN_OR_001__153041-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC20_P37_S52_Full_A24_C59mX_E15_20220129_015324_574779-zlib.ome.tiff', 'CRC2/data_CRC20_19510_C20_US_SCAN_OR_001__153341-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC21_P37_S58_Full_A24_C59nX_E15_20220224_011058_014787-zlib.ome.tiff', 'CRC2/data_CRC21_19510_C21_US_SCAN_OR_001__153607-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC22_P37_S59_Full_A24_C59nX_E15_20220224_011113_455637-zlib.ome.tiff', 'CRC2/data_CRC22_19510_C22_US_SCAN_OR_001__092420-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC23_P37_S60_Full_A24_C59nX_E15_20220224_011127_971497-zlib.ome.tiff', 'CRC2/data_CRC23_19510_C23_US_SCAN_OR_001__154147-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC24_P37_S61_Full_A24_C59nX_E15_20220224_011149_079291-zlib.ome.tiff', 'CRC2/data_CRC24_19510_C24_US_SCAN_OR_001__091904-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC25_P37_S62_Full_A24_C59nX_E15_20220224_011204_784145-zlib.ome.tiff', 'CRC2/data_CRC25_19510_C25_US_SCAN_OR_001__154712-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC26_P37_S63_Full_A24_C59nX_E15_20220224_011246_458738-zlib.ome.tiff', 'CRC2/data_CRC26_19510_C26_US_SCAN_OR_001__092131-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC27_P37_S64_Full_A24_C59nX_E15_20220224_011259_841605-zlib.ome.tiff', 'CRC2/data_CRC27_19510_C27_US_SCAN_OR_001__155205-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC28_P37_S65_Full_A24_C59nX_E15_20220224_011333_386280-zlib.ome.tiff', 'CRC2/data_CRC28_19510_C28_US_SCAN_OR_001__155413-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC29_P37_S66_Full_A24_C59nX_E15_20220224_011348_519133-zlib.ome.tiff', 'CRC2/data_CRC29_19510_C29_US_SCAN_OR_001__155859-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC30_P37_S67_Full_A24_C59nX_E15_20220224_011408_506939-zlib.ome.tiff', 'CRC2/data_CRC30_19510_C30_US_SCAN_OR_001__155702-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC31_P37_S74_Full_A24_C59qX_E15_20220302_234837_137590-zlib.ome.tiff', 'CRC2/data_CRC31_19510_C31_US_SCAN_OR_001__160203-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC32_P37_S75_Full_A24_C59qX_E15_20220302_235001_586560-zlib.ome.tiff', 'CRC2/data_CRC32_19510_C32_US_SCAN_OR_001__160434-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC33_01_P37_S76_01_A24_C59qX_E15_20220302_235136_561323-zlib.ome.tiff', 'CRC2/data_CRC33_01_19510_C33_US_SCAN_OR_001__160715-2-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC33_02_P37_S76_02_A24_C59qX_E15_20220302_235158_533766-zlib.ome.tiff', 'CRC2/data_CRC33_02_19510_C33_US_SCAN_OR_001__160715-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC34_P37_S77_Full_A24_C59qX_E15_20220302_235222_359806-zlib.ome.tiff', 'CRC2/data_CRC34_19510_C34_US_SCAN_OR_001__160949-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC35_P37_S78_Full_A24_C59qX_E15_20220302_235239_498836-zlib.ome.tiff', 'CRC2/data_CRC35_19510_C35_US_SCAN_OR_001__161209-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC36_P37_S79_Full_A24_C59qX_E15_20220302_235254_496641-zlib.ome.tiff', 'CRC2/data_CRC36_19510_C36_US_SCAN_OR_001__161442-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC37_P37_S80_Full_A24_C59qX_E15_20220307_235159_333000-zlib.ome.tiff', 'CRC2/data_CRC37_19510_C37_US_SCAN_OR_001__161733-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC38_P37_S81_Full_A24_C59qX_E15_20220302_235331_704703-zlib.ome.tiff', 'CRC2/data_CRC38_19510_C38_US_SCAN_OR_001__162018-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC39_P37_S82_Full_A24_C59qX_E15_20220304_200614_832683-zlib.ome.tiff', 'CRC2/data_CRC39_19510_C39_US_SCAN_OR_001__162343-registered.ome.tif'),\n",
    "    ('CRC2/H&E/data_CRC40_P37_S83_Full_A24_C59qX_E15_20220304_200429_490805-zlib.ome.tiff', 'CRC2/data_CRC40_19510_P37-S83_C40_US_SCAN_OR_001__163912-registered.ome.tif'),\n",
    "]\n",
    "\n",
    "# -------- Helpers --------\n",
    "def _pair_tag_from_paths(vpath: Path, rpath: Path, idx: int) -> str:\n",
    "    \"\"\"Create a short, unique tag for saving files.\"\"\"\n",
    "    m = re.search(r\"(CRC\\d+(_\\d+)?)\", vpath.name)\n",
    "    base = m.group(1) if m else f\"pair_{idx+1:02d}\"\n",
    "    return base\n",
    "\n",
    "def compute_counts_all_tiles(real_res, virt_res):\n",
    "    \"\"\"\n",
    "    Compare virtual vs real predictions on the overlapping tile grid.\n",
    "    Keeps ALL tiles (including BACKGROUND).\n",
    "    Returns (counts[T,T], T, tissue_names_full, stats_dict).\n",
    "    \"\"\"\n",
    "    Ny_r, Nx_r = real_res[\"grid_shape\"]\n",
    "    Ny_v, Nx_v = virt_res[\"grid_shape\"]\n",
    "    Ny_o, Nx_o = min(Ny_r, Ny_v), min(Nx_r, Nx_v)\n",
    "\n",
    "    grid_real = real_res[\"pred_grid\"][:Ny_o, :Nx_o]\n",
    "    grid_virt = virt_res[\"pred_grid\"][:Ny_o, :Nx_o]\n",
    "    flat_real = grid_real.ravel()\n",
    "    flat_virt = grid_virt.ravel()\n",
    "\n",
    "    # Keep ALL tiles (incl. BACK)\n",
    "    mask = np.ones_like(flat_real, dtype=bool)\n",
    "    virt_t = flat_virt[mask]\n",
    "    real_t = flat_real[mask]\n",
    "\n",
    "    # Use natural IDs 0..(num_classes-1)\n",
    "    tissue_ids = list(range(num_classes))\n",
    "    id2pos = {cid: i for i, cid in enumerate(tissue_ids)}\n",
    "    T = len(tissue_ids)\n",
    "    tissue_names_full = [id_to_full[cid] for cid in tissue_ids]\n",
    "\n",
    "    if virt_t.size == 0:\n",
    "        counts = np.zeros((T, T), dtype=int)\n",
    "    else:\n",
    "        virt_idx = np.fromiter((id2pos[int(c)] for c in virt_t), dtype=np.int32, count=virt_t.size)\n",
    "        real_idx = np.fromiter((id2pos[int(c)] for c in real_t), dtype=np.int32, count=real_t.size)\n",
    "        pair_index = virt_idx * T + real_idx\n",
    "        counts = np.bincount(pair_index, minlength=T*T).reshape(T, T)\n",
    "\n",
    "    agree = int(np.trace(counts))\n",
    "    total = int(counts.sum())\n",
    "    acc = (agree / total) if total > 0 else float('nan')\n",
    "\n",
    "    stats = {\n",
    "        \"Ny_r\": Ny_r, \"Nx_r\": Nx_r,\n",
    "        \"Ny_v\": Ny_v, \"Nx_v\": Nx_v,\n",
    "        \"Ny_o\": Ny_o, \"Nx_o\": Nx_o,\n",
    "        \"tiles_total_overlap\": Ny_o * Nx_o,\n",
    "        \"tiles_used\": int(mask.sum()),\n",
    "        \"agree_all\": agree,\n",
    "        \"total_all\": total,\n",
    "        \"acc_alltiles\": acc,\n",
    "    }\n",
    "    return counts, T, tissue_names_full, stats\n",
    "\n",
    "def save_pair_outputs(pair_tag, counts, tissue_names_full, acc_all):\n",
    "    \"\"\"\n",
    "    Save CSVs and a heatmap (rows=virtual, cols=real) for ALL tiles (incl. BACK).\n",
    "    \"\"\"\n",
    "    T = len(tissue_names_full)\n",
    "\n",
    "    # Counts CSV\n",
    "    counts_df = pd.DataFrame(counts, index=tissue_names_full, columns=tissue_names_full)\n",
    "    counts_csv = SAVE_DIR / f\"{pair_tag}_ALL_TILES_virtual_rows_vs_real_cols_COUNTS.csv\"\n",
    "    counts_df.to_csv(counts_csv)\n",
    "\n",
    "    # Row-normalized integer percent CSV (virtual rows sum to 1)\n",
    "    row_sums = counts.sum(axis=1, keepdims=True)\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        row_norm = counts / np.clip(row_sums, 1, None)\n",
    "    row_pct_int = np.rint(row_norm * 100).astype(int)\n",
    "    rowpct_df = pd.DataFrame(row_pct_int, index=tissue_names_full, columns=tissue_names_full)\n",
    "    rowpct_csv = SAVE_DIR / f\"{pair_tag}_ALL_TILES_virtual_to_real_ROW_PERCENT_INT.csv\"\n",
    "    rowpct_df.to_csv(rowpct_csv)\n",
    "\n",
    "    # Heatmap figure\n",
    "    CMAP = \"viridis\"\n",
    "    FIGSIZE = (8, 8)\n",
    "    TITLE_FS, LABEL_FS, TICK_FS, ANN_FS, CB_FS = 16, 14, 12, 14, 12\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "    im = ax.imshow(row_norm, vmin=0.0, vmax=1.0, cmap=CMAP, aspect=\"equal\", interpolation=\"nearest\")\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"{pair_tag} — Virtual (rows) → Real (cols) — ALL tiles (incl. BACK) — \"\n",
    "        f\"Overall accuracy: {acc_all*100:.1f}\",\n",
    "        fontsize=TITLE_FS\n",
    "    )\n",
    "    ax.set_xlabel(\"Real H&E classes\", fontsize=LABEL_FS)\n",
    "    ax.set_ylabel(\"Virtual H&E classes\", fontsize=LABEL_FS)\n",
    "    ax.set_xticks(np.arange(T)); ax.set_yticks(np.arange(T))\n",
    "    ax.set_xticklabels(tissue_names_full, rotation=45, ha=\"right\", fontsize=TICK_FS)\n",
    "    ax.set_yticklabels(tissue_names_full, fontsize=TICK_FS)\n",
    "\n",
    "    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(\"Percent of virtual class tiles\", fontsize=CB_FS)\n",
    "    cb_ticks = np.linspace(0, 1, 6)\n",
    "    cbar.set_ticks(cb_ticks)\n",
    "    cbar.set_ticklabels([f\"{int(t*100)}\" for t in cb_ticks])\n",
    "    for t in cbar.ax.get_yticklabels(): t.set_fontsize(CB_FS)\n",
    "\n",
    "    # Annotate cells with integer percent; bold diagonal\n",
    "    for i in range(T):\n",
    "        for j in range(T):\n",
    "            v = row_norm[i, j]\n",
    "            txt_color = \"white\" if v < 0.5 else \"black\"\n",
    "            ax.text(j, i, f\"{row_pct_int[i, j]}\",\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    fontsize=ANN_FS, fontweight=(\"bold\" if i == j else \"normal\"),\n",
    "                    color=txt_color)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(SAVE_DIR / f\"{pair_tag}_ALL_TILES_virtual_to_real_row_percent_heatmap.pdf\")\n",
    "    fig.savefig(SAVE_DIR / f\"{pair_tag}_ALL_TILES_virtual_to_real_row_percent_heatmap.png\", dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return {\"counts_csv\": counts_csv, \"rowpct_csv\": rowpct_csv}\n",
    "\n",
    "# -------- Run all pairs --------\n",
    "pair_results = []\n",
    "for idx, (virt_path_str, real_path_str) in enumerate(image_pairs):\n",
    "    vpath, rpath = Path(virt_path_str), Path(real_path_str)\n",
    "    pair_tag = _pair_tag_from_paths(vpath, rpath, idx)\n",
    "\n",
    "    try:\n",
    "        print(f\"\\n=== Processing {pair_tag} ===\")\n",
    "        virt_res = run_wsi(vpath, tag=f\"{pair_tag}_virtual\")\n",
    "        real_res = run_wsi(rpath, tag=f\"{pair_tag}_real\")\n",
    "\n",
    "        counts, T, tissue_names_full, stats = compute_counts_all_tiles(real_res, virt_res)\n",
    "        outs = save_pair_outputs(pair_tag, counts, tissue_names_full, stats[\"acc_alltiles\"])\n",
    "\n",
    "        print(f\"Tiles (real Ny×Nx): {stats['Ny_r']}×{stats['Nx_r']} | (virt Ny×Nx): {stats['Ny_v']}×{stats['Nx_v']}\")\n",
    "        if (stats['Ny_r'], stats['Nx_r']) != (stats['Ny_v'], stats['Nx_v']):\n",
    "            print(f\"Overlap used: {stats['Ny_o']}×{stats['Nx_o']}\")\n",
    "        print(f\"Tiles used (ALL, incl. BACK): {stats['tiles_used']} / {stats['tiles_total_overlap']}\")\n",
    "        print(f\"Accuracy (diag/total, ALL): {stats['agree_all']}/{stats['total_all']} = {stats['acc_alltiles']*100:.1f}\")\n",
    "\n",
    "        pair_results.append({\n",
    "            \"pair_tag\": pair_tag,\n",
    "            \"counts\": counts,\n",
    "            \"tissue_names_full\": tissue_names_full,\n",
    "            \"stats\": stats,\n",
    "            \"files\": outs,\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {pair_tag}: {e}\")\n",
    "        pair_results.append({\n",
    "            \"pair_tag\": pair_tag,\n",
    "            \"error\": str(e),\n",
    "        })\n",
    "\n",
    "print(f\"\\nDone. Processed {len(pair_results)} pairs.\")\n",
    "# ==================== end batch block ====================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb365be-48d7-407e-8f4a-a4dd8cd00b74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "OUT_PDF = \"figures/Heatmap.pdf\"\n",
    "OUT_CSV = \"PerClass_Recall_column_normalized.csv\"  # diagonal (recall per real class, %)\n",
    "CMAP = \"Blues\"\n",
    "FIGSIZE = (8, 8)\n",
    "TITLE_FS, LABEL_FS, TICK_FS, ANN_FS, CB_FS = 18, 16, 14, 16, 14\n",
    "\n",
    "def _plot_heatmap(mat, class_names, title, save_pdf_path=None, show=False):\n",
    "    T = len(class_names)\n",
    "    pct_int = np.rint(mat * 100).astype(int)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "    im = ax.imshow(mat, vmin=0.0, vmax=1.0, cmap=CMAP, aspect=\"equal\", interpolation=\"nearest\")\n",
    "    ax.set_title(title, fontsize=TITLE_FS)\n",
    "    ax.set_xlabel(\"Predictions on real H&E\", fontsize=LABEL_FS)\n",
    "    ax.set_ylabel(\"Predictions on virtual H&E\", fontsize=LABEL_FS)\n",
    "    ax.set_xticks(np.arange(T)); ax.set_yticks(np.arange(T))\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha=\"right\", fontsize=TICK_FS)\n",
    "    ax.set_yticklabels(class_names, fontsize=TICK_FS)\n",
    "\n",
    "    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(\"Percent of real H&E prediction\", fontsize=CB_FS)  # column-normalized\n",
    "    cb_ticks = np.linspace(0, 1, 6)\n",
    "    cbar.set_ticks(cb_ticks)\n",
    "    cbar.set_ticklabels([f\"{int(t*100)}\" for t in cb_ticks])\n",
    "    for t in cbar.ax.get_yticklabels():\n",
    "        t.set_fontsize(CB_FS)\n",
    "\n",
    "    # annotate cells with integer %\n",
    "    for i in range(T):\n",
    "        for j in range(T):\n",
    "            v = mat[i, j]\n",
    "            txt_color = \"black\" if v < 0.5 else \"white\"\n",
    "            ax.text(j, i, f\"{pct_int[i, j]}\",\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    fontsize=ANN_FS, fontweight=(\"bold\" if i == j else \"normal\"),\n",
    "                    color=txt_color)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save_pdf_path is not None:\n",
    "        # ensure directory of the PDF exists (current working dir or nested path)\n",
    "        Path(save_pdf_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        fig.savefig(save_pdf_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "        print(f\"Saved {save_pdf_path}\")\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "\n",
    "# Plot & save\n",
    "_plot_heatmap(\n",
    "    col_norm_micro, class_names,\n",
    "    title=\"Column-normalized correspondence\",\n",
    "    save_pdf_path=OUT_PDF,\n",
    "    show=True,  # set False if you don't want inline display\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c656bd-bc7d-4189-8dcc-80fcfc790f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pypdf import PdfReader, PdfWriter, Transformation\n",
    "\n",
    "reader1 = PdfReader(\"figures/wsi_comparison.pdf\")\n",
    "reader2 = PdfReader(\"figures/Heatmap.pdf\")\n",
    "\n",
    "page1 = reader1.pages[0]   # base\n",
    "page2 = reader2.pages[0]   # overlay\n",
    "\n",
    "# Define a transformation: shrink to 50%, move right and down\n",
    "transformation = (\n",
    "    Transformation()\n",
    "    .scale(sx=0.75, sy=0.75)      # scale down\n",
    "    .translate(tx=580, ty=0)  # shift right (x) and down (y)\n",
    ")\n",
    "\n",
    "# Apply the transformation to page2 before merging\n",
    "page1.merge_transformed_page(page2, transformation)\n",
    "\n",
    "# Write output\n",
    "writer = PdfWriter()\n",
    "writer.add_page(page1)\n",
    "\n",
    "with open(\"overlay.pdf\", \"wb\") as f:\n",
    "    writer.write(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3cb864-b1b2-4bc6-868b-3e29f7f9e702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftest",
   "language": "python",
   "name": "tftest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
