{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87fb6e7-f3bc-4113-b73e-dd94c674ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tifffile\n",
    "from PIL import Image\n",
    "from matplotlib.collections import PolyCollection  # remove if unused\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import pearsonr\n",
    "from skimage import color, filters, io, util\n",
    "from skimage.measure import label\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f1c74-4b2e-4cd6-bf12-c49ee0d90e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to count the number of segmented regions in an image\n",
    "def count_segments(image_path):\n",
    "    # Read the image\n",
    "    image = tifffile.imread(image_path)\n",
    "    # Label the connected components\n",
    "    labeled_image = label(image)\n",
    "    # Count the number of unique labels, excluding the background (label 0)\n",
    "    num_segments = len(np.unique(labeled_image)) - 1\n",
    "    return num_segments\n",
    "\n",
    "# Directories\n",
    "segmentations_dir = \"IMC_Bodenmiller/OMEandSingleCellMasks/SegmentationsStarDist/\"\n",
    "masks_dir = \"IMC_Bodenmiller/OMEandSingleCellMasks/OMEnMasks/Basel_Zuri_masks/\"\n",
    "\n",
    "# Collect TIFF files in the Segmentations folder\n",
    "seg_files = sorted(f for f in os.listdir(segmentations_dir) if f.endswith(\".tiff\"))\n",
    "\n",
    "segmentations_counts_imc = []\n",
    "masks_counts_imc = []\n",
    "\n",
    "for seg_file in seg_files:\n",
    "    seg_path = os.path.join(segmentations_dir, seg_file)\n",
    "\n",
    "    # Split filename into base + extension\n",
    "    base_name, ext = os.path.splitext(seg_file)  # e.g. \"xxx\", \".tiff\"\n",
    "    \n",
    "    print(base_name)\n",
    "\n",
    "    # Construct the corresponding _masks filename\n",
    "    # e.g. \"xxx\" + \"_masks\" + \".tiff\" -> \"xxx_masks.tiff\"\n",
    "    mask_file = base_name + \"_maks\" + ext\n",
    "    mask_path = os.path.join(masks_dir, mask_file)\n",
    "    \n",
    "    # print(basel_mask_file)\n",
    "    # print(basel_mask_path)\n",
    "\n",
    "    # Check if the corresponding file exists in the Basel_Zuri_masks folder\n",
    "    if not os.path.exists(mask_path):\n",
    "        print(f\"Skipping '{seg_file}' because matching file '{mask_file}' not found.\")\n",
    "        continue\n",
    "\n",
    "    # Count segments for the segmentation\n",
    "    seg_count = count_segments(seg_path)\n",
    "    # Count segments for the Basel_Zuri_mask\n",
    "    count = count_segments(mask_path)\n",
    "\n",
    "    segmentations_counts_imc.append(seg_count)\n",
    "    masks_counts_imc.append(count)\n",
    "\n",
    "# (Optional) Check if we have equal numbers\n",
    "if len(segmentations_counts_imc) != len(masks_counts_imc):\n",
    "    raise ValueError(\"Mismatch in the number of processed images between the two folders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d778ae2-9f65-409b-9f68-d9f99529356b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to count the number of segmented regions in a TIFF image\n",
    "def count_segments(image_path):\n",
    "    \"\"\"\n",
    "    Count the number of segmented regions in a TIFF image.\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    image = tifffile.imread(image_path)\n",
    "    # Label the connected components\n",
    "    labeled_image = label(image)\n",
    "    # Count the number of unique labels, excluding the background (label 0)\n",
    "    num_segments = len(np.unique(labeled_image)) - 1\n",
    "    return num_segments\n",
    "\n",
    "# Function to count the number of cells in a PNG mask\n",
    "def count_cells_in_png(image_path, threshold=0):\n",
    "    \"\"\"\n",
    "    Count the number of cells in a PNG mask by thresholding and labeling.\n",
    "    \"\"\"\n",
    "    # Read the PNG image\n",
    "    image = imread(image_path, as_gray=True)  # Load as grayscale\n",
    "    # Threshold the image\n",
    "    binary_mask = image > threshold\n",
    "    # Label the connected components\n",
    "    labeled_image = label(binary_mask)\n",
    "    # Count the number of unique labels, excluding the background (label 0)\n",
    "    num_cells = len(np.unique(labeled_image)) - 1\n",
    "    return num_cells\n",
    "\n",
    "# Directories\n",
    "segmentations_dir = \"MultiplexFluorescentAnnotations/Vectra/SegmentationsStarDist/\"\n",
    "masks_dir = \"MultiplexFluorescentAnnotations/Vectra/\"\n",
    "\n",
    "# Collect TIFF files in the Segmentations folder\n",
    "seg_files = sorted(f for f in os.listdir(segmentations_dir) if f.endswith(\".tif\"))\n",
    "\n",
    "segmentations_counts_vectra = []\n",
    "masks_counts_vectra = []\n",
    "\n",
    "for seg_file in seg_files:\n",
    "    seg_path = os.path.join(segmentations_dir, seg_file)\n",
    "\n",
    "    # Split filename into base + extension\n",
    "    base_name, ext = os.path.splitext(seg_file)  # e.g., \"xxx\", \".tiff\"\n",
    "    \n",
    "    print(f\"Processing segmentation: {base_name}\")\n",
    "\n",
    "    # Construct the corresponding ground truth mask filename\n",
    "    # Replace \"-Crop_Tif\" with \"-Crop_Dapi_Mask_Png\" and add \".png\"\n",
    "    ground_truth_file = base_name.replace(\"-Crop_Tif\", \"-Crop_Dapi_Mask_Png\") + \".png\"\n",
    "\n",
    "    # Search for the ground truth mask file in all subdirectories of masks_dir\n",
    "    ground_truth_path = None\n",
    "    for root, _, files in os.walk(masks_dir):\n",
    "        if ground_truth_file in files:\n",
    "            ground_truth_path = os.path.join(root, ground_truth_file)\n",
    "            break\n",
    "            \n",
    "            \n",
    "    if not ground_truth_path:\n",
    "        ground_truth_file = base_name.replace(\"-Crop_Tif\", \"-Crop_Cell_Mask_Png\") + \".png\"\n",
    "\n",
    "        # Search for the ground truth mask file in all subdirectories of masks_dir\n",
    "        ground_truth_path = None\n",
    "        for root, _, files in os.walk(masks_dir):\n",
    "            if ground_truth_file in files:\n",
    "                ground_truth_path = os.path.join(root, ground_truth_file)\n",
    "                break\n",
    "                \n",
    "    \n",
    "    # If no corresponding ground truth mask is found, skip this file\n",
    "    if not ground_truth_path:\n",
    "        print(f\"Skipping '{seg_file}' because matching ground truth file '{ground_truth_file}' not found.\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Found '{ground_truth_file}'\")\n",
    "        \n",
    "\n",
    "    # Count segments for the segmentation\n",
    "    seg_count = count_segments(seg_path)\n",
    "    # Count cells in the ground truth mask\n",
    "    count = count_cells_in_png(ground_truth_path)\n",
    "    \n",
    "    print(f\"seg_count '{seg_count}' count '{count}'\")\n",
    "    \n",
    "    if \"P03-10012(56707.13038)650,600\" in ground_truth_file:\n",
    "        print(\"segmentation mismatch\")\n",
    "        continue\n",
    "        \n",
    "    if \"P13-10002(45819.10401)2250,500\" in ground_truth_file:\n",
    "        print(\"unusable ground truth mask\")\n",
    "        continue\n",
    "        \n",
    "    segmentations_counts_vectra.append(seg_count)\n",
    "    masks_counts_vectra.append(count)\n",
    "\n",
    "# Check if we have equal numbers\n",
    "if len(segmentations_counts_vectra) != len(masks_counts_vectra):\n",
    "    raise ValueError(\"Mismatch in the number of processed images between the two folders.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac092cd-efea-4ad5-977b-3f45547d064b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_image(path):\n",
    "    with Image.open(path) as im:\n",
    "        im_rgb = im.convert(\"RGB\")\n",
    "        arr = np.array(im_rgb, dtype=np.uint8)\n",
    "    return arr\n",
    "\n",
    "def luminance_image(img_rgb):\n",
    "    # skimage.color.rgb2gray returns float64 in [0,1] from uint8 RGB\n",
    "    return color.rgb2gray(img_rgb)  # shape (H,W), float64\n",
    "\n",
    "def edge_strength_gray(gray_img):\n",
    "    # Sobel magnitude; float64 ~ [0,1]-ish\n",
    "    sob = filters.sobel(gray_img)\n",
    "    return float(np.mean(sob))\n",
    "\n",
    "def noise_level_gray(gray_img, sigma=1.0):\n",
    "    # Estimate high-frequency residual std\n",
    "    gray_f = util.img_as_float32(gray_img)  # [0,1]\n",
    "    blur = gaussian_filter(gray_f, sigma=sigma)\n",
    "    residual = gray_f - blur\n",
    "    return float(np.std(residual))\n",
    "\n",
    "def list_tiffs(folder_path):\n",
    "    return sorted([\n",
    "        f for f in os.listdir(folder_path)\n",
    "        if f.lower().endswith((\".tif\", \".tiff\"))\n",
    "    ])\n",
    "\n",
    "\n",
    "def compute_efficiency_dataframe(folders):\n",
    "    unfiltered_dir = folders[\"unfiltered\"]\n",
    "    median_dir = folders[\"median\"]\n",
    "    deep_dir = folders[\"deep_learning\"]\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # iterate over unfiltered filenames as anchors\n",
    "    uf_files = list_tiffs(unfiltered_dir)\n",
    "\n",
    "    for fname in uf_files:\n",
    "        print(fname)\n",
    "        # unfiltered\n",
    "        uf_path = os.path.join(unfiltered_dir, fname)\n",
    "\n",
    "        img_u = load_image(uf_path)\n",
    "        gray_u = luminance_image(img_u)\n",
    "\n",
    "        edge_u = edge_strength_gray(gray_u)\n",
    "        noise_u = noise_level_gray(gray_u)\n",
    "\n",
    "\n",
    "        # median\n",
    "        med_path = os.path.join(median_dir, fname)\n",
    "\n",
    "        img_m = load_image(med_path)\n",
    "        gray_m = luminance_image(img_m)\n",
    "\n",
    "        edge_m = edge_strength_gray(gray_m)\n",
    "        noise_m = noise_level_gray(gray_m)\n",
    "\n",
    "        # normalized-to-baseline efficiency\n",
    "        eff_norm_m = (edge_m / edge_u) / (noise_m / noise_u)\n",
    "\n",
    "        rows.append({\n",
    "            \"file\": fname,\n",
    "            \"method\": \"Median\",\n",
    "            \"edge_strength_gray\": edge_m,\n",
    "            \"noise_level_gray\": noise_m,\n",
    "            \"efficiency_norm\": eff_norm_m,\n",
    "        })\n",
    "\n",
    "\n",
    "        # deep learning\n",
    "        dl_path = os.path.join(deep_dir, fname)\n",
    "\n",
    "        img_d = load_image(dl_path)\n",
    "        gray_d = luminance_image(img_d)\n",
    "\n",
    "        edge_d = edge_strength_gray(gray_d)\n",
    "        noise_d = noise_level_gray(gray_d)\n",
    "\n",
    "        eff_norm_d = (edge_d / edge_u) / (noise_d / noise_u)\n",
    "\n",
    "        rows.append({\n",
    "            \"file\": fname,\n",
    "            \"method\": \"Deep learning\",\n",
    "            \"edge_strength_gray\": edge_d,\n",
    "            \"noise_level_gray\": noise_d,\n",
    "            \"efficiency_norm\": eff_norm_d,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "    \n",
    "folders = {\n",
    "    \"unfiltered\":    \"IMC_Bodenmiller/OMEandSingleCellMasks/H&E_unfiltered\",\n",
    "    \"median\":        \"IMC_Bodenmiller/OMEandSingleCellMasks/H&E_median\",\n",
    "    \"deep_learning\": \"IMC_Bodenmiller/OMEandSingleCellMasks/H&E_deep_learning\",\n",
    "}\n",
    "\n",
    "df_eff = compute_efficiency_dataframe(folders)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245848e8-bdee-4229-868b-ce01ce4c142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))  # 1 row, 3 columns\n",
    "\n",
    "# =======================\n",
    "# Subplot 1: Violin Plot\n",
    "# =======================\n",
    "\n",
    "def get_violin_line_x_limits_from_collection(collection, y_val):\n",
    "    intersections = []\n",
    "    for path in collection.get_paths():\n",
    "        vertices = path.vertices\n",
    "        n = len(vertices)\n",
    "        for i in range(n - 1):\n",
    "            v1 = vertices[i]\n",
    "            v2 = vertices[i + 1]\n",
    "            y1, y2 = v1[1], v2[1]\n",
    "            if (y1 - y_val) * (y2 - y_val) < 0:\n",
    "                x1, x2 = v1[0], v2[0]\n",
    "                t = (y_val - y1) / (y2 - y1)\n",
    "                x_intersect = x1 + t * (x2 - x1)\n",
    "                intersections.append(x_intersect)\n",
    "            elif y1 == y_val:\n",
    "                intersections.append(v1[0])\n",
    "    if intersections:\n",
    "        return min(intersections), max(intersections)\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "ax_efficiency = axs[0]\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "violin_palette = [\"#f2e5ff\", \"#ffe5f4\"]\n",
    "\n",
    "\n",
    "methods = [\"Median\", \"Deep learning\"]\n",
    "\n",
    "data_list = [\n",
    "    df_eff.query(\"method == 'Median'\")[\"efficiency_norm\"].dropna().values,\n",
    "    df_eff.query(\"method == 'Deep learning'\")[\"efficiency_norm\"].dropna().values\n",
    "]\n",
    "\n",
    "\n",
    "positions = np.arange(len(data_list))\n",
    "\n",
    "violin_parts = ax_efficiency.violinplot(\n",
    "    data_list,\n",
    "    positions=positions,\n",
    "    widths=0.9,\n",
    "    showmeans=False,\n",
    "    showmedians=False,\n",
    "    showextrema=False\n",
    ")\n",
    "\n",
    "# Style violins\n",
    "for i, pc in enumerate(violin_parts[\"bodies\"]):\n",
    "    pc.set_facecolor(violin_palette[i % len(violin_palette)])\n",
    "    pc.set_edgecolor(\"black\")\n",
    "    pc.set_alpha(1)\n",
    "\n",
    "# Axis settings\n",
    "ax_efficiency.set_xticks(positions)\n",
    "ax_efficiency.set_xticklabels(methods, fontsize=13)\n",
    "ax_efficiency.set_title(\"Enhancement efficiency\", fontsize=18)\n",
    "ax_efficiency.grid(False)\n",
    "ax_efficiency.minorticks_off()\n",
    "\n",
    "ax_efficiency.tick_params(axis=\"y\", which=\"major\",\n",
    "                       direction=\"out\", length=6, width=1.5, color=\"black\")\n",
    "ax_efficiency.tick_params(axis=\"y\", which=\"minor\",\n",
    "                       direction=\"out\", length=3, width=1.0, color=\"black\")\n",
    "ax_efficiency.tick_params(axis=\"x\", which=\"both\",\n",
    "                       bottom=False, top=False)\n",
    "\n",
    "# Mean Â± SD bars & annotation\n",
    "for i, m in enumerate(methods):\n",
    "    data = df_eff[df_eff[\"method\"] == m][\"efficiency_norm\"].dropna()\n",
    "    if len(data) == 0:\n",
    "        continue\n",
    "    mean_val = data.mean()\n",
    "    sd_val = data.std()\n",
    "    pc = violin_parts[\"bodies\"][i]\n",
    "\n",
    "    x_min_mean, x_max_mean = get_violin_line_x_limits_from_collection(pc, mean_val)\n",
    "    x_min_hi,   x_max_hi   = get_violin_line_x_limits_from_collection(pc, mean_val + sd_val)\n",
    "    x_min_lo,   x_max_lo   = get_violin_line_x_limits_from_collection(pc, mean_val - sd_val)\n",
    "\n",
    "    # fallbacks if that y-level isn't sampled on the outline\n",
    "    if None in (x_min_mean, x_max_mean):\n",
    "        x_center = positions[i]\n",
    "        x_min_mean, x_max_mean = x_center - 0.4, x_center + 0.4\n",
    "    if None in (x_min_hi, x_max_hi):\n",
    "        x_min_hi, x_max_hi = x_min_mean, x_max_mean\n",
    "    if None in (x_min_lo, x_max_lo):\n",
    "        x_min_lo, x_max_lo = x_min_mean, x_max_mean\n",
    "\n",
    "    # mean line (black solid)\n",
    "    ax_efficiency.plot([x_min_mean, x_max_mean], [mean_val, mean_val],\n",
    "                    color=\"black\", linestyle=\"-\", linewidth=1)\n",
    "    # +SD and -SD (gray dashed)\n",
    "    ax_efficiency.plot([x_min_hi, x_max_hi], [mean_val + sd_val, mean_val + sd_val],\n",
    "                    color=\"grey\", linestyle=\"--\", linewidth=1)\n",
    "    ax_efficiency.plot([x_min_lo, x_max_lo], [mean_val - sd_val, mean_val - sd_val],\n",
    "                    color=\"grey\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    # annotate mean\n",
    "    ax_efficiency.text((x_min_mean + x_max_mean) / 2, mean_val,\n",
    "                    f\"{mean_val:.2f}\", ha=\"center\", va=\"bottom\",\n",
    "                    color=\"black\", fontsize=12)\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Subplot 2: Scatter Plot for IMC (Ground Truth on x-axis)\n",
    "# =======================\n",
    "ax_imc = axs[1]\n",
    "\n",
    "# Compute Pearson correlation for IMC\n",
    "correlation_imc, p_value_imc = pearsonr(masks_counts_imc, segmentations_counts_imc)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=masks_counts_imc,           # ground truth on x-axis\n",
    "    y=segmentations_counts_imc,   # segmentation counts on y-axis\n",
    "    alpha=0.1,\n",
    "    edgecolor=None,\n",
    "    ax=ax_imc\n",
    ")\n",
    "ax_imc.set_xlabel('Number of cells in ground truth', fontsize=13)\n",
    "ax_imc.set_ylabel('Number of cells in segmentations', fontsize=13)\n",
    "ax_imc.set_title(\"IMC\", fontsize=18)\n",
    "\n",
    "# Annotate the correlation result\n",
    "text_x_imc = 350\n",
    "text_y_imc = 6300\n",
    "if p_value_imc < 0.001:\n",
    "    ax_imc.text(text_x_imc, text_y_imc, f'r = {correlation_imc:.2f}, p < 0.001', fontsize=18, color='black')\n",
    "else:\n",
    "    ax_imc.text(text_x_imc, text_y_imc, f'r = {correlation_imc:.2f}, p = {p_value_imc:.2e}', fontsize=18, color='black')\n",
    "\n",
    "# Set limits and force equal aspect ratio\n",
    "ax_imc.set_xlim(0, 7000)\n",
    "ax_imc.set_ylim(0, 7000)\n",
    "ax_imc.set_aspect('equal', adjustable='box')\n",
    "ax_imc.set_yticks(np.arange(0, 7000, 2000))\n",
    "ax_imc.set_xticks(np.arange(0, 7000, 2000))\n",
    "\n",
    "# =======================\n",
    "# Subplot 3: Scatter Plot for Multiplex Fluorescence (Ground Truth on x-axis)\n",
    "# =======================\n",
    "ax_vectra = axs[2]\n",
    "\n",
    "# Compute Pearson correlation for Multiplex Fluorescence\n",
    "correlation_vectra, p_value_vectra = pearsonr(masks_counts_vectra, segmentations_counts_vectra)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=masks_counts_vectra,           # ground truth on x-axis\n",
    "    y=segmentations_counts_vectra,   # segmentation counts on y-axis\n",
    "    alpha=0.3,\n",
    "    edgecolor=None,\n",
    "    ax=ax_vectra\n",
    ")\n",
    "ax_vectra.set_xlabel('Number of cells in ground truth', fontsize=13)\n",
    "ax_vectra.set_ylabel('Number of cells in segmentations', fontsize=13)\n",
    "ax_vectra.set_title(\"Multiplex Fluorescence\", fontsize=18)\n",
    "\n",
    "text_x_vectra = 45\n",
    "text_y_vectra = 810\n",
    "if p_value_vectra < 0.001:\n",
    "    ax_vectra.text(text_x_vectra, text_y_vectra, f'r = {correlation_vectra:.2f}, p < 0.001', fontsize=18, color='black')\n",
    "else:\n",
    "    ax_vectra.text(text_x_vectra, text_y_vectra, f'r = {correlation_vectra:.2f}, p = {p_value_vectra:.2e}', fontsize=18, color='black')\n",
    "\n",
    "ax_vectra.set_xlim(0, 900)\n",
    "ax_vectra.set_ylim(0, 900)\n",
    "ax_vectra.set_aspect('equal', adjustable='box')\n",
    "ax_vectra.set_yticks(np.arange(0, 900, 200))\n",
    "ax_vectra.set_xticks(np.arange(0, 900, 200))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/combined_plots.pdf\", format=\"pdf\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
